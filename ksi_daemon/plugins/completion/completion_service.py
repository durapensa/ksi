#!/usr/bin/env python3\n"""\nCompletion Service Plugin V2\n\nEnhanced completion service that integrates with:\n- Async completion queue with priority support\n- Conversation lock management\n- Event-driven injection routing\n- Circuit breaker safety mechanisms\n"""\n\nimport asyncio\nimport json\nimport os\nimport time\nimport uuid\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, List\nimport logging\nimport pluggy\n\nimport anyio\nimport litellm\n\nfrom ksi_common.logging import get_logger\nfrom ksi_daemon.plugin_utils import plugin_metadata\nfrom ksi_common import TimestampManager, create_completion_response, parse_completion_response\nfrom ksi_daemon.config import config\nfrom ksi_daemon.event_taxonomy import CLAUDE_EVENTS, format_claude_event\n\n# Import injection systems\nfrom ksi_daemon.plugins.injection.injection_router import queue_completion_with_injection\nfrom ksi_daemon.plugins.injection.circuit_breakers import check_completion_allowed\n\n# Import claude_cli_litellm_provider to ensure provider registration\nfrom ksi_daemon.plugins.completion import claude_cli_litellm_provider\n\n# Plugin metadata\nplugin_metadata("completion_service", version="3.0.0",\n                description="Enhanced LLM completion service with queue and injection support")\n\n# Hook implementation marker\nhookimpl = pluggy.HookimplMarker("ksi")\n\n# Module state\nlogger = get_logger("completion_service")\nactive_completions: Dict[str, Dict[str, Any]] = {}\n\n# Per-session queue management for fork prevention\nsession_processors: Dict[str, asyncio.Queue] = {}  # session_id -> Queue\nactive_sessions: set = set()  # Currently processing sessions\n\n# Structured concurrency with anyio - created on demand\ncompletion_task_group = None\ntask_group_context = None\n\n# Event emitter reference (set during startup)\nevent_emitter = None\n\n\ndef get_completion_task_group():\n    """Get the completion task group (must be called after service startup)."""\n    if completion_task_group is None:\n        raise RuntimeError("Completion service not ready - task group not available")\n    return completion_task_group\n\n\ndef ensure_directories():\n    """Ensure required directories exist."""\n    config.ensure_directories()\n\n\ndef save_completion_response(response_data: Dict[str, Any]) -> None:\n    """\n    Save standardized completion response to session file.\n    \n    Args:\n        response_data: Standardized completion response from create_completion_response\n    """\n    try:\n        # Parse the completion response to extract session_id\n        completion_response = parse_completion_response(response_data)\n        session_id = completion_response.get_session_id()\n        \n        if not session_id:\n            logger.warning("No session_id in completion response, cannot save to session file")\n            return\n        \n        # Ensure responses directory exists\n        responses_dir = config.response_log_dir\n        responses_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Session file path\n        session_file = responses_dir / f"{session_id}.jsonl"\n        \n        # Append response to session file\n        with open(session_file, 'a', encoding='utf-8') as f:\n            f.write(json.dumps(response_data) + '\n')\n        \n        logger.debug(f"Saved completion response to {session_file}")\n        \n    except Exception as e:\n        logger.error(f"Failed to save completion response: {e}", exc_info=True)\n\n\n# Hook implementations\n@hookimpl(trylast=True)  # Run after core services are ready  \ndef ksi_startup(config):\n    """Initialize completion service on startup."""\n    ensure_directories()\n    logger.debug("DEBUG: Testing if debug logs work in completion service")\n    logger.info("Smart hybrid completion service with anyio structured concurrency - event-driven with per-session fork prevention")\n    return {"status": "completion_service_anyio_smart_hybrid_ready"}\n\n\n\nasync def manage_completion_service():\n    """Long-running service to manage anyio task group for completions."""\n    global completion_task_group, task_group_context\n    \n    logger.info("Starting completion service manager task")\n    \n    try:\n        # Create and enter the task group context\n        async with anyio.create_task_group() as tg:\n            completion_task_group = tg\n            logger.info("Completion service ready with task group")\n            \n            # Keep the service running until cancelled\n            await anyio.sleep_forever()\n            \n    except anyio.get_cancelled_exc_class():\n        logger.info("Completion service manager cancelled")\n        raise\n    except Exception as e:\n        logger.error(f"Completion service error: {e}", exc_info=True)\n        raise\n    finally:\n        completion_task_group = None\n        logger.info("Completion service manager stopped")\n\n\n@hookimpl\ndef ksi_ready():\n    """Return the completion service manager task."""\n    logger.info("Completion service requesting service manager task")\n    \n    return {\n        "service": "completion_service",\n        "tasks": [\n            {\n                "name": "service_manager",\n                "coroutine": manage_completion_service()\n            }\n        ]\n    }\n\n\n\n\n@hookimpl\ndef ksi_handle_event(event_name: str, data: Dict[str, Any], context: Dict[str, Any]):\n    """Handle completion-related events."""\n    \n    if event_name == "completion:async":\n        logger.info(f"Received completion:async event with data: {data}")\n        # Smart hybrid: event-driven + per-session fork prevention\n        # Create a coroutine wrapper for consistent async handling\n        async def _handle_async():\n            return await handle_async_completion_smart(data, context)\n        return _handle_async()\n    \n    elif event_name == "completion:cancel":\n        # Cancel an active completion\n        request_id = data.get("request_id")\n        if request_id in active_completions:\n            # Cancellation with queue not yet implemented\n            del active_completions[request_id]\n            return {"status": "cancelled"}\n        return {"status": "not_found"}\n    \n    elif event_name == "completion:status":\n        # anyio smart hybrid architecture status\n        return {\n            "architecture": "anyio_smart_hybrid",\n            "task_group_active": completion_task_group is not None,\n            "active_count": len(active_completions),\n            "active_requests": list(active_completions.keys()),\n            "active_sessions": list(active_sessions),\n            "session_queues": {\n                session_id: queue.qsize() \n                for session_id, queue in session_processors.items()\n            },\n            "session_queue_count": len(session_processors)\n        }\n    \n    elif event_name == "completion:session_status":\n        # Detailed per-session status\n        session_id = data.get("session_id")\n        if not session_id:\n            return {"error": "session_id required"}\n            \n        return {\n            "session_id": session_id,\n            "active": session_id in active_sessions,\n            "queued": session_processors.get(session_id, asyncio.Queue()).qsize() if session_id in session_processors else 0,\n            "has_queue": session_id in session_processors\n        }\n    \n    return None\n\n\nasync def handle_completion_request(data: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:\n    """Handle completion request (original logic preserved)."""\n    \n    prompt = data.get("prompt", "")\n    model = data.get("model", "claude-cli/sonnet")\n    session_id = data.get("session_id")\n    temperature = data.get("temperature", 0.7)\n    max_tokens = data.get("max_tokens", 4096)\n    client_id = data.get("client_id")\n    request_id = data.get("request_id", str(uuid.uuid4()))\n    \n    if not prompt:\n        return {"error": "No prompt provided"}\n    \n    # Check for pending injections if session_id provided\n    if session_id and event_emitter:\n        prepend_injections = []\n        append_injections = []\n        \n        # Pop all pending injections for this session\n        while True:\n            result = await event_emitter("async_state:pop", {\n                "namespace": "injection",\n                "key": session_id\n            })\n            \n            if not result or not result.get("found"):\n                break\n                \n            injection_data = result.get("data", {})\n            position = injection_data.get("position", "prepend")\n            content = injection_data.get("content", "")\n            \n            if position == "prepend":\n                prepend_injections.append(content)\n            else:  # postscript\n                append_injections.append(content)\n        \n        # Apply injections to prompt\n        if prepend_injections:\n            prompt = "\n\n".join(prepend_injections) + "\n\n" + prompt\n            logger.info(f"Applied {len(prepend_injections)} prepend injections to session {session_id}")\n        \n        if append_injections:\n            prompt = prompt + "\n\n" + "\n\n".join(append_injections)\n            logger.info(f"Applied {len(append_injections)} postscript injections to session {session_id}")\n    \n    start_time = time.time()\n    \n    try:\n        # Prepare messages\n        messages = data.get("messages", [])\n        if not messages and prompt:\n            messages = [{"role": "user", "content": prompt}]\n        \n        # Just pass model through - no mapping\n        # Prepare litellm parameters\n        completion_params = {\n            "model": model,\n            "messages": messages,\n            "temperature": temperature,\n            "max_tokens": max_tokens\n        }\n        \n        # Add session ID as metadata for claude-cli provider\n        if session_id:\n            completion_params["metadata"] = {"session_id": session_id}\n        \n        # Call LiteLLM\n        response = await litellm.acompletion(**completion_params)\n        \n        # Calculate duration\n        duration_ms = int((time.time() - start_time) * 1000)\n        \n        # Extract response\n        raw_response = {}\n        \n        if model.startswith("claude-cli/"):\n            # Claude CLI returns JSON string in content\n            content = response.choices[0].message.content\n            if isinstance(content, str) and content.strip().startswith('{'):\n                try:\n                    raw_response = json.loads(content)\n                except json.JSONDecodeError:\n                    raw_response = {\n                        "result": content,\n                        "session_id": session_id,\n                        "model": model\n                    }\n            else:\n                raw_response = {\n                    "result": content,\n                    "session_id": session_id,\n                    "model": model\n                }\n        else:\n            # Other providers\n            raw_response = response.model_dump() if hasattr(response, 'model_dump') else dict(response)\n        \n        # Create standardized response\n        completion_response = create_completion_response(\n            provider="claude-cli" if model.startswith("claude-cli/") else "unknown",\n            raw_response=raw_response,\n            request_id=request_id,\n            client_id=client_id,\n            duration_ms=duration_ms\n        )\n        \n        # Save response to session file\n        response_data = completion_response.to_dict()\n        save_completion_response(response_data)\n        \n        # Extract actual session_id from response (may differ due to forking)\n        actual_session_id = raw_response.get('session_id', session_id)\n        response_data['session_id'] = actual_session_id\n        \n        return response_data\n        \n    except Exception as e:\n        logger.error(f"Completion error: {e}", exc_info=True)\n        duration_ms = int((time.time() - start_time) * 1000)\n        \n        # Return error in standardized format\n        error_response = create_completion_response(\n            provider="claude-cli" if model.startswith("claude-cli/") else "unknown",\n            raw_response={\n                "error": str(e),\n                "error_type": type(e).__name__\n            },\n            request_id=request_id,\n            client_id=client_id,\n            duration_ms=duration_ms\n        )\n        \n        result = error_response.to_dict()\n        result["error"] = str(e)\n        result["status"] = "error"\n        \n        save_completion_response(result)\n        \n        return result\n\n\nasync def handle_async_completion_smart(data: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:\n    """Smart hybrid completion handling - event-driven + per-session fork prevention."""\n    \n    # Generate request ID if not provided\n    request_id = data.get('request_id', str(uuid.uuid4()))\n    data['request_id'] = request_id\n    session_id = data.get('session_id')\n    \n    # Check if injection is requested\n    injection_config = data.get("injection_config")\n    if injection_config and injection_config.get('enabled'):\n        # Store injection metadata with injection router\n        request_id = queue_completion_with_injection(data)\n        data['request_id'] = request_id\n    \n    # Smart routing based on session state\n    if not session_id:\n        # No session ID = no fork risk = immediate processing\n        task_group = get_completion_task_group()\n        task_group.start_soon(process_single_completion, data, context)\n        logger.info(f"Processing sessionless completion {request_id} immediately")\n        \n        return {\n            "request_id": request_id,\n            "status": "processing",\n            "reason": "no_session",\n            "message": "Processing immediately - no fork risk"\n        }\n    \n    elif session_id in active_sessions:\n        # Session busy = queue to prevent fork\n        if session_id not in session_processors:\n            # Create per-session queue on demand\n            session_processors[session_id] = asyncio.Queue()\n            task_group = get_completion_task_group()\n            task_group.start_soon(process_session_queue, session_id)\n            logger.info(f"Created queue processor for session {session_id}")\n        \n        # Queue the request\n        await session_processors[session_id].put(data)\n        logger.info(f"Queued completion {request_id} for busy session {session_id}")\n        \n        return {\n            "request_id": request_id,\n            "status": "queued",\n            "reason": "session_busy",\n            "session_id": session_id,\n            "message": "Queued to prevent conversation fork"\n        }\n    \n    else:\n        # Session free = immediate processing with lock\n        task_group = get_completion_task_group()\n        task_group.start_soon(process_completion_with_session_lock, data, context)\n        logger.info(f"Processing completion {request_id} for free session {session_id}")\n        \n        return {\n            "request_id": request_id,\n            "status": "processing", \n            "session_id": session_id,\n            "message": "Processing immediately"\n        }\n\n\nasync def process_session_queue(session_id: str) -> None:\n    """Process queued requests for a specific session - prevents forks."""\n    \n    logger.info(f"Starting session queue processor for {session_id}")\n    queue = session_processors[session_id]\n    \n    try:\n        while True:\n            # Wait for next request for this session\n            request_data = await queue.get()\n            \n            logger.info(f"Processing queued request for session {session_id}")\n            \n            # Process with session lock\n            await process_completion_with_session_lock(request_data, {})\n            \n            # Mark task done\n            queue.task_done()\n            \n    except asyncio.CancelledError:\n        logger.info(f"Session queue processor for {session_id} cancelled")\n        raise\n    except Exception as e:\n        logger.error(f"Session queue error for {session_id}: {e}", exc_info=True)\n        # Continue processing queue\n    finally:\n        # Cleanup session queue when done\n        if session_id in session_processors:\n            del session_processors[session_id]\n        logger.info(f"Session queue processor for {session_id} stopped")\n\n\nasync def process_completion_with_session_lock(data: Dict[str, Any], context: Dict[str, Any]) -> None:\n    """Process completion with session locking to prevent forks."""\n    \n    session_id = data.get('session_id')\n    request_id = data.get('request_id', str(uuid.uuid4()))\n    \n    try:\n        # Acquire session lock\n        if session_id:\n            active_sessions.add(session_id)\n            logger.debug(f"Acquired session lock for {session_id}")\n            \n        # Process the completion\n        await process_single_completion(data, context)\n        \n    finally:\n        # Always release session lock\n        if session_id:\n            active_sessions.discard(session_id)\n            logger.debug(f"Released session lock for {session_id}")\n\n\nasync def process_single_completion(data: Dict[str, Any], context: Dict[str, Any]) -> None:\n    """Process a single completion request - core logic."""\n    \n    request_id = data.get('request_id', str(uuid.uuid4()))\n    \n    logger.debug(f"Processing completion request {request_id}")\n    \n    try:\n        # Store as active\n        active_completions[request_id] = {\n            "data": data,\n            "started_at": TimestampManager.timestamp_utc()\n        }\n        \n        # Emit progress event\n        if event_emitter and callable(event_emitter):\n            await event_emitter("completion:progress", {\n                "request_id": request_id,\n                "status": "processing",\n                "message": "Processing completion"\n            }, {})\n        \n        # Process the completion\n        result = await handle_completion_request(data, context)\n        \n        # Add request ID to result\n        result["request_id"] = request_id\n        \n        # Emit result event (will trigger injection router)\n        if event_emitter and callable(event_emitter):\n            logger.debug(f"Emitting completion:result event for {request_id}")\n            emit_result = await event_emitter("completion:result", result, {})\n            logger.debug(f"completion:result emission result: {emit_result}")\n        else:\n            logger.error("event_emitter not available or not callable")\n        \n        logger.info(f"Completed request {request_id}")\n        \n    except Exception as e:\n        logger.error(f"Completion error for {request_id}: {e}", exc_info=True)\n        # Emit error event\n        if event_emitter and callable(event_emitter):\n            await event_emitter("completion:error", {\n                "request_id": request_id,\n                "error": str(e)\n            }, {})\n    \n    finally:\n        # Clean up\n        active_completions.pop(request_id, None)\n\n\n\n@hookimpl\ndef ksi_plugin_context(context):\n    """Receive plugin context with event emitter."""\n    global event_emitter\n    event_emitter = context.get("emit_event")\n\n\n@hookimpl\ndef ksi_shutdown():\n    """Clean up on shutdown."""\n    logger.info(f"anyio smart hybrid completion service stopped - {len(active_completions)} active tasks, {len(session_processors)} session queues")\n    \n    return {\n        "status": "completion_service_anyio_smart_hybrid_stopped",\n        "active_tasks": len(active_completions),\n        "session_queues": len(session_processors),\n        "architecture": "anyio_smart_hybrid"\n    }\n\n\n# Module-level marker for plugin discovery\nksi_plugin = True