@article{Wei_2022,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and others},
  journal={NeurIPS},
  year={2022}
}

@article{Liu_2024,
  title={Lost in the middle: How language models use long contexts},
  author={Liu, Nelson F and others},
  journal={TACL},
  year={2024}
}

@article{Kwon_2023,
  title={Efficient memory management for large language model serving with pagedattention},
  author={Kwon, Woosuk and others},
  journal={SOSP},
  year={2023}
}

@article{Stiennon_2020,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and others},
  journal={NeurIPS},
  year={2020}
}

@article{Ouyang_2022,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and others},
  journal={NeurIPS},
  year={2022}
}

@article{Dao_2022,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and others},
  journal={NeurIPS},
  year={2022}
}

@article{Fu_2023,
  title={Chain-of-thought hub: A continuous effort to measure large language models' reasoning performance},
  author={Fu, Yao and others},
  journal={arXiv preprint},
  year={2023}
}

@misc{Anthropic_2024,
  title={Claude API Pricing},
  author={Anthropic},
  year={2024},
  url={https://www.anthropic.com/pricing}
}
